model_list:
  # OpenAI Models
  - model_name: gpt-4.1-mini-2025-04-14
    litellm_params:
      model: openai/gpt-4.1-mini-2025-04-14
      api_key: os.environ/OPENAI_API_KEY
      
  - model_name: o4-mini-2025-04-16
    litellm_params:
      model: openai/o4-mini-2025-04-16
      api_key: os.environ/OPENAI_API_KEY

  # Claude Models (Anthropic)
  - model_name: claude-3-5-haiku-20241022
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      
  - model_name: claude-3-haiku-20240307
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY

  # Google Gemini Models
  - model_name: gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: os.environ/GEMINI_API_KEY

# Server configuration
litellm_settings:
  # Enable request/response logging
  callbacks: ["langfuse_otel"]  # Optional: for tracking
  langfuse_public_key: os.environ/LANGFUSE_PUB_KEY # Project 1
  langfuse_secret: os.environ/LANGFUSE_PRIVATE_KEY # Project 1
  langfuse_host: os.environ/LANGFUSE_OTEL_API
  # Rate limiting (optional)
  rpm: 100
  max_budget: 10.0  # USD per month
  
  # Enable streaming for all models
  stream: true
  
  # Timeout settings
  request_timeout: 600
  
  # Enable model fallbacks
  enable_model_fallback: true

# Optional: Router settings for load balancing
router_settings:
  routing_strategy: "least-busy"  # Options: simple-shuffle, least-busy, usage-based-routing
  model_group_alias:
    gpt-4-group:
      - gpt-4
      - gpt-4-turbo
    claude-group:
      - claude-3-5-haiku-20241022
      - claude-3-haiku-20240307
    gemini-group:
      - gemini-2.0-flash

# General settings
general_settings:
  custom_auth: custom_auth.user_api_key_auth